#!/usr/bin/env python
# coding: utf-8

# # ä½ çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ
# 
# åœ¨æ­¤é¡¹ç›®ä¸­ï¼Œä½ å°†æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¹¶ç”¨è¯¥ç½‘ç»œé¢„æµ‹æ¯æ—¥è‡ªè¡Œè½¦ç§Ÿå®¢äººæ•°ã€‚æˆ‘ä»¬æä¾›äº†ä¸€äº›ä»£ç ï¼Œä½†æ˜¯éœ€è¦ä½ æ¥å®ç°ç¥ç»ç½‘ç»œï¼ˆå¤§éƒ¨åˆ†å†…å®¹ï¼‰ã€‚æäº¤æ­¤é¡¹ç›®åï¼Œæ¬¢è¿è¿›ä¸€æ­¥æ¢ç´¢è¯¥æ•°æ®å’Œæ¨¡å‹ã€‚

# In[1]:


get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


# ## åŠ è½½å’Œå‡†å¤‡æ•°æ®
# 
# æ„å»ºç¥ç»ç½‘ç»œçš„å…³é”®ä¸€æ­¥æ˜¯æ­£ç¡®åœ°å‡†å¤‡æ•°æ®ã€‚ä¸åŒå°ºåº¦çº§åˆ«çš„å˜é‡ä½¿ç½‘ç»œéš¾ä»¥é«˜æ•ˆåœ°æŒæ¡æ­£ç¡®çš„æƒé‡ã€‚æˆ‘ä»¬åœ¨ä¸‹æ–¹å·²ç»æä¾›äº†åŠ è½½å’Œå‡†å¤‡æ•°æ®çš„ä»£ç ã€‚ä½ å¾ˆå¿«å°†è¿›ä¸€æ­¥å­¦ä¹ è¿™äº›ä»£ç ï¼

# In[2]:


data_path = 'Bike-Sharing-Dataset/hour.csv'

rides = pd.read_csv(data_path)


# In[3]:


rides.head()


# ## æ•°æ®ç®€ä»‹
# 
# æ­¤æ•°æ®é›†åŒ…å«çš„æ˜¯ä» 2011 å¹´ 1 æœˆ 1 æ—¥åˆ° 2012 å¹´ 12 æœˆ 31 æ—¥æœŸé—´æ¯å¤©æ¯å°æ—¶çš„éª‘è½¦äººæ•°ã€‚éª‘è½¦ç”¨æˆ·åˆ†æˆä¸´æ—¶ç”¨æˆ·å’Œæ³¨å†Œç”¨æˆ·ï¼Œcnt åˆ—æ˜¯éª‘è½¦ç”¨æˆ·æ•°æ±‡æ€»åˆ—ã€‚ä½ å¯ä»¥åœ¨ä¸Šæ–¹çœ‹åˆ°å‰å‡ è¡Œæ•°æ®ã€‚
# 
# ä¸‹å›¾å±•ç¤ºçš„æ˜¯æ•°æ®é›†ä¸­å‰ 10 å¤©å·¦å³çš„éª‘è½¦äººæ•°ï¼ˆæŸäº›å¤©ä¸ä¸€å®šæ˜¯ 24 ä¸ªæ¡ç›®ï¼Œæ‰€ä»¥ä¸æ˜¯ç²¾ç¡®çš„ 10 å¤©ï¼‰ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°æ¯å°æ—¶ç§Ÿé‡‘ã€‚è¿™äº›æ•°æ®å¾ˆå¤æ‚ï¼å‘¨æœ«çš„éª‘è¡Œäººæ•°å°‘äº›ï¼Œå·¥ä½œæ—¥ä¸Šä¸‹ç­æœŸé—´æ˜¯éª‘è¡Œé«˜å³°æœŸã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä»ä¸Šæ–¹çš„æ•°æ®ä¸­çœ‹åˆ°æ¸©åº¦ã€æ¹¿åº¦å’Œé£é€Ÿä¿¡æ¯ï¼Œæ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½ä¼šå½±å“éª‘è¡Œäººæ•°ã€‚ä½ éœ€è¦ç”¨ä½ çš„æ¨¡å‹å±•ç¤ºæ‰€æœ‰è¿™äº›æ•°æ®ã€‚

# In[4]:


rides[:24*10].plot(x='dteday', y='cnt')


# ### è™šæ‹Ÿå˜é‡ï¼ˆå“‘å˜é‡ï¼‰
# 
# ä¸‹é¢æ˜¯ä¸€äº›åˆ†ç±»å˜é‡ï¼Œä¾‹å¦‚å­£èŠ‚ã€å¤©æ°”ã€æœˆä»½ã€‚è¦åœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­åŒ…å«è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºäºŒè¿›åˆ¶è™šæ‹Ÿå˜é‡ã€‚ç”¨ Pandas åº“ä¸­çš„Â `get_dummies()` å°±å¯ä»¥è½»æ¾å®ç°ã€‚

# In[6]:


dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']
for each in dummy_fields:
    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)
    rides = pd.concat([rides, dummies], axis=1)

fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', 
                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']
data = rides.drop(fields_to_drop, axis=1)
data.head()


# ### è°ƒæ•´ç›®æ ‡å˜é‡
# 
# ä¸ºäº†æ›´è½»æ¾åœ°è®­ç»ƒç½‘ç»œï¼Œæˆ‘ä»¬å°†å¯¹æ¯ä¸ªè¿ç»­å˜é‡æ ‡å‡†åŒ–ï¼Œå³è½¬æ¢å’Œè°ƒæ•´å˜é‡ï¼Œä½¿å®ƒä»¬çš„å‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ã€‚
# 
# æˆ‘ä»¬ä¼šä¿å­˜æ¢ç®—å› å­ï¼Œä»¥ä¾¿å½“æˆ‘ä»¬ä½¿ç”¨ç½‘ç»œè¿›è¡Œé¢„æµ‹æ—¶å¯ä»¥è¿˜åŸæ•°æ®ã€‚

# In[8]:


quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']
# Store scalings in a dictionary so we can convert back later
scaled_features = {}
for each in quant_features:
    mean, std = data[each].mean(), data[each].std()
    scaled_features[each] = [mean, std]
    data.loc[:, each] = (data[each] - mean)/std


# ### å°†æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯æ•°æ®é›†
# 
# æˆ‘ä»¬å°†å¤§çº¦æœ€å 21 å¤©çš„æ•°æ®ä¿å­˜ä¸ºæµ‹è¯•æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®é›†ä¼šåœ¨è®­ç»ƒå®Œç½‘ç»œåä½¿ç”¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä¸å®é™…çš„éª‘è¡Œäººæ•°è¿›è¡Œå¯¹æ¯”ã€‚

# In[9]:


# Save data for approximately the last 21 days 
test_data = data[-21*24:]

# Now remove the test data from the data set 
data = data[:-21*24]

# Separate the data into features and targets
target_fields = ['cnt', 'casual', 'registered']
features, targets = data.drop(target_fields, axis=1), data[target_fields]
test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]


# æˆ‘ä»¬å°†æ•°æ®æ‹†åˆ†ä¸ºä¸¤ä¸ªæ•°æ®é›†ï¼Œä¸€ä¸ªç”¨ä½œè®­ç»ƒï¼Œä¸€ä¸ªåœ¨ç½‘ç»œè®­ç»ƒå®Œåç”¨æ¥éªŒè¯ç½‘ç»œã€‚å› ä¸ºæ•°æ®æ˜¯æœ‰æ—¶é—´åºåˆ—ç‰¹æ€§çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨å†å²æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç„¶åå°è¯•é¢„æµ‹æœªæ¥æ•°æ®ï¼ˆéªŒè¯æ•°æ®é›†ï¼‰ã€‚

# In[10]:


# Hold out the last 60 days or so of the remaining data as a validation set
train_features, train_targets = features[:-60*24], targets[:-60*24]
val_features, val_targets = features[-60*24:], targets[-60*24:]


# ## å¼€å§‹æ„å»ºç½‘ç»œ
# 
# ä¸‹é¢ä½ å°†æ„å»ºè‡ªå·±çš„ç½‘ç»œã€‚æˆ‘ä»¬å·²ç»æ„å»ºå¥½ç»“æ„å’Œåå‘ä¼ é€’éƒ¨åˆ†ã€‚ä½ å°†å®ç°ç½‘ç»œçš„å‰å‘ä¼ é€’éƒ¨åˆ†ã€‚è¿˜éœ€è¦è®¾ç½®è¶…å‚æ•°ï¼šå­¦ä¹ é€Ÿç‡ã€éšè—å•å…ƒçš„æ•°é‡ï¼Œä»¥åŠè®­ç»ƒä¼ é€’æ•°é‡ã€‚
# 
# <img src="assets/neural_network.png" width=300px>
# 
# è¯¥ç½‘ç»œæœ‰ä¸¤ä¸ªå±‚çº§ï¼Œä¸€ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ã€‚éšè—å±‚çº§å°†ä½¿ç”¨ S å‹å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚è¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç”¨äºé€’å½’ï¼ŒèŠ‚ç‚¹çš„è¾“å‡ºå’ŒèŠ‚ç‚¹çš„è¾“å…¥ç›¸åŒã€‚å³æ¿€æ´»å‡½æ•°æ˜¯Â $f(x)=x$ã€‚è¿™ç§å‡½æ•°è·å¾—è¾“å…¥ä¿¡å·ï¼Œå¹¶ç”Ÿæˆè¾“å‡ºä¿¡å·ï¼Œä½†æ˜¯ä¼šè€ƒè™‘é˜ˆå€¼ï¼Œç§°ä¸ºæ¿€æ´»å‡½æ•°ã€‚æˆ‘ä»¬å®Œæˆç½‘ç»œçš„æ¯ä¸ªå±‚çº§ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºã€‚ä¸€ä¸ªå±‚çº§çš„æ‰€æœ‰è¾“å‡ºå˜æˆä¸‹ä¸€å±‚çº§ç¥ç»å…ƒçš„è¾“å…¥ã€‚è¿™ä¸€æµç¨‹å«åšå‰å‘ä¼ æ’­ï¼ˆforward propagationï¼‰ã€‚
# 
# æˆ‘ä»¬åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨æƒé‡å°†ä¿¡å·ä»è¾“å…¥å±‚ä¼ æ’­åˆ°è¾“å‡ºå±‚ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨æƒé‡å°†é”™è¯¯ä»è¾“å‡ºå±‚ä¼ æ’­å›ç½‘ç»œï¼Œä»¥ä¾¿æ›´æ–°æƒé‡ã€‚è¿™å«åšåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ã€‚
# 
# > **æç¤º**ï¼šä½ éœ€è¦ä¸ºåå‘ä¼ æ’­å®ç°è®¡ç®—è¾“å‡ºæ¿€æ´»å‡½æ•° ($f(x) = x$) çš„å¯¼æ•°ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰å¾®ç§¯åˆ†ï¼Œå…¶å®è¯¥å‡½æ•°å°±ç­‰åŒäºç­‰å¼Â $y = x$ã€‚è¯¥ç­‰å¼çš„æ–œç‡æ˜¯å¤šå°‘ï¼Ÿä¹Ÿå°±æ˜¯å¯¼æ•°Â $f(x)$ã€‚
# 
# 
# ä½ éœ€è¦å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
# 
# 1. å®ç° S å‹æ¿€æ´»å‡½æ•°ã€‚å°† `__init__`Â ä¸­çš„ `self.activation_function`  è®¾ä¸ºä½ çš„ S å‹å‡½æ•°ã€‚
# 2. åœ¨ `train`Â æ–¹æ³•ä¸­å®ç°å‰å‘ä¼ é€’ã€‚
# 3. åœ¨ `train`Â æ–¹æ³•ä¸­å®ç°åå‘ä¼ æ’­ç®—æ³•ï¼ŒåŒ…æ‹¬è®¡ç®—è¾“å‡ºé”™è¯¯ã€‚
# 4. åœ¨ `run`Â æ–¹æ³•ä¸­å®ç°å‰å‘ä¼ é€’ã€‚
# 
#   

# In[11]:


class NeuralNetwork(object):
    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):
        # Set number of nodes in input, hidden and output layers.
        self.input_nodes = input_nodes
        self.hidden_nodes = hidden_nodes
        self.output_nodes = output_nodes

        # Initialize weights
        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, 
                                       (self.input_nodes, self.hidden_nodes))

        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, 
                                       (self.hidden_nodes, self.output_nodes))
        self.lr = learning_rate
        
        #### TODO: Set self.activation_function to your implemented sigmoid function ####
        #
        # Note: in Python, you can define a function with a lambda expression,
        # as shown below.
        self.activation_function = lambda x : 1 / (1 + np.exp(-x))  # Replace 0 with your sigmoid calculation.
        
        ### If the lambda code above is not something you're familiar with,
        # You can uncomment out the following three lines and put your 
        # implementation there instead.
        #
        #def sigmoid(x):
        #    return 0  # Replace 0 with your sigmoid calculation here
        #self.activation_function = sigmoid
                    
    
    def train(self, features, targets):
        ''' Train the network on batch of features and targets. 
        
            Arguments
            ---------
            
            features: 2D array, each row is one data record, each column is a feature
            targets: 1D array of target values
        
        '''
        n_records = features.shape[0]
        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)
        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)
        for X, y in zip(features, targets):
            #### Implement the forward pass here ####
            ### Forward pass ###
            # TODO: Hidden layer - Replace these values with your calculations.
            hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer
            hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer

            # TODO: Output layer - Replace these values with your calculations.
            final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer
            final_outputs = final_inputs # signals from final output layer è¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç”¨äºé€’å½’ï¼ŒèŠ‚ç‚¹çš„è¾“å‡ºå’ŒèŠ‚ç‚¹çš„è¾“å…¥ç›¸åŒã€‚å³æ¿€æ´»å‡½æ•°æ˜¯  ğ‘“(ğ‘¥)=ğ‘¥
            
            #### Implement the backward pass here ####
            ### Backward pass ###

            # TODO: Output error - Replace this value with your calculations.
            error = y - final_outputs # Output layer error is the difference between desired target and actual output.
            
            # TODO: Calculate the hidden layer's contribution to the error            
            hidden_error = np.dot(self.weights_hidden_to_output, error) 
            
            # TODO: Backpropagated error terms - Replace these values with your calculations.
            output_error_term = error * 1.0 # y=x å¯¼æ•°æ˜¯ 1
            hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)

            # Weight step (input to hidden)
            delta_weights_i_h += hidden_error_term * X[:,None]
            # Weight step (hidden to output)
            delta_weights_h_o += output_error_term * hidden_outputs[:,None]

        # TODO: Update the weights - Replace these values with your calculations.
        self.weights_hidden_to_output += self.lr*delta_weights_h_o/n_records # update hidden-to-output weights with gradient descent step
        self.weights_input_to_hidden += self.lr*delta_weights_i_h/n_records # update input-to-hidden weights with gradient descent step
 
    def run(self, features):
        ''' Run a forward pass through the network with input features 
        
            Arguments
            ---------
            features: 1D array of feature values
        '''
        
        #### Implement the forward pass here ####
        # TODO: Hidden layer - replace these values with the appropriate calculations.
        hidden_inputs = np.dot(features, self.weights_input_to_hidden) # signals into hidden layer
        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer
        
        # TODO: Output layer - Replace these values with the appropriate calculations.
        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer
        final_outputs = final_inputs # signals from final output layer 
        
        return final_outputs


# In[12]:


def MSE(y, Y):
    return np.mean((y-Y)**2)


# ## å•å…ƒæµ‹è¯•
# 
# è¿è¡Œè¿™äº›å•å…ƒæµ‹è¯•ï¼Œæ£€æŸ¥ä½ çš„ç½‘ç»œå®ç°æ˜¯å¦æ­£ç¡®ã€‚è¿™æ ·å¯ä»¥å¸®åŠ©ä½ ç¡®ä¿ç½‘ç»œå·²æ­£ç¡®å®ç°ï¼Œç„¶åå†å¼€å§‹è®­ç»ƒç½‘ç»œã€‚è¿™äº›æµ‹è¯•å¿…é¡»æˆåŠŸæ‰èƒ½é€šè¿‡æ­¤é¡¹ç›®ã€‚

# In[13]:


import unittest

inputs = np.array([[0.5, -0.2, 0.1]])
targets = np.array([[0.4]])
test_w_i_h = np.array([[0.1, -0.2],
                       [0.4, 0.5],
                       [-0.3, 0.2]])
test_w_h_o = np.array([[0.3],
                       [-0.1]])

class TestMethods(unittest.TestCase):
    
    ##########
    # Unit tests for data loading
    ##########
    
    def test_data_path(self):
        # Test that file path to dataset has been unaltered
        self.assertTrue(data_path.lower() == 'bike-sharing-dataset/hour.csv')
        
    def test_data_loaded(self):
        # Test that data frame loaded
        self.assertTrue(isinstance(rides, pd.DataFrame))
    
    ##########
    # Unit tests for network functionality
    ##########

    def test_activation(self):
        network = NeuralNetwork(3, 2, 1, 0.5)
        # Test that the activation function is a sigmoid
        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))

    def test_train(self):
        # Test that weights are updated correctly on training
        network = NeuralNetwork(3, 2, 1, 0.5)
        network.weights_input_to_hidden = test_w_i_h.copy()
        network.weights_hidden_to_output = test_w_h_o.copy()
        
        network.train(inputs, targets)
        self.assertTrue(np.allclose(network.weights_hidden_to_output, 
                                    np.array([[ 0.37275328], 
                                              [-0.03172939]])))
        self.assertTrue(np.allclose(network.weights_input_to_hidden,
                                    np.array([[ 0.10562014, -0.20185996], 
                                              [0.39775194, 0.50074398], 
                                              [-0.29887597, 0.19962801]])))

    def test_run(self):
        # Test correctness of run method
        network = NeuralNetwork(3, 2, 1, 0.5)
        network.weights_input_to_hidden = test_w_i_h.copy()
        network.weights_hidden_to_output = test_w_h_o.copy()

        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))

suite = unittest.TestLoader().loadTestsFromModule(TestMethods())
unittest.TextTestRunner().run(suite)


# ## è®­ç»ƒç½‘ç»œ
# 
# ç°åœ¨ä½ å°†è®¾ç½®ç½‘ç»œçš„è¶…å‚æ•°ã€‚ç­–ç•¥æ˜¯è®¾ç½®çš„è¶…å‚æ•°ä½¿è®­ç»ƒé›†ä¸Šçš„é”™è¯¯å¾ˆå°ä½†æ˜¯æ•°æ®ä¸ä¼šè¿‡æ‹Ÿåˆã€‚å¦‚æœç½‘ç»œè®­ç»ƒæ—¶é—´å¤ªé•¿ï¼Œæˆ–è€…æœ‰å¤ªå¤šçš„éšè—èŠ‚ç‚¹ï¼Œå¯èƒ½å°±ä¼šè¿‡äºé’ˆå¯¹ç‰¹å®šè®­ç»ƒé›†ï¼Œæ— æ³•æ³›åŒ–åˆ°éªŒè¯æ•°æ®é›†ã€‚å³å½“è®­ç»ƒé›†çš„æŸå¤±é™ä½æ—¶ï¼ŒéªŒè¯é›†çš„æŸå¤±å°†å¼€å§‹å¢å¤§ã€‚
# 
# ä½ è¿˜å°†é‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™ (SGD) æ–¹æ³•è®­ç»ƒç½‘ç»œã€‚å¯¹äºæ¯æ¬¡è®­ç»ƒï¼Œéƒ½è·å–éšæœºæ ·æœ¬æ•°æ®ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ•°æ®é›†ã€‚ä¸æ™®é€šæ¢¯åº¦ä¸‹é™ç›¸æ¯”ï¼Œè®­ç»ƒæ¬¡æ•°è¦æ›´å¤šï¼Œä½†æ˜¯æ¯æ¬¡æ—¶é—´æ›´çŸ­ã€‚è¿™æ ·çš„è¯ï¼Œç½‘ç»œè®­ç»ƒæ•ˆç‡æ›´é«˜ã€‚ç¨åä½ å°†è¯¦ç»†äº†è§£ SGDã€‚
# 
# 
# ### é€‰æ‹©è¿­ä»£æ¬¡æ•°
# 
# ä¹Ÿå°±æ˜¯è®­ç»ƒç½‘ç»œæ—¶ä»è®­ç»ƒæ•°æ®ä¸­æŠ½æ ·çš„æ‰¹æ¬¡æ•°é‡ã€‚è¿­ä»£æ¬¡æ•°è¶Šå¤šï¼Œæ¨¡å‹å°±ä¸æ•°æ®è¶Šæ‹Ÿåˆã€‚ä½†æ˜¯ï¼Œå¦‚æœè¿­ä»£æ¬¡æ•°å¤ªå¤šï¼Œæ¨¡å‹å°±æ— æ³•å¾ˆå¥½åœ°æ³›åŒ–åˆ°å…¶ä»–æ•°æ®ï¼Œè¿™å«åšè¿‡æ‹Ÿåˆã€‚ä½ éœ€è¦é€‰æ‹©ä¸€ä¸ªä½¿è®­ç»ƒæŸå¤±å¾ˆä½å¹¶ä¸”éªŒè¯æŸå¤±ä¿æŒä¸­ç­‰æ°´å¹³çš„æ•°å­—ã€‚å½“ä½ å¼€å§‹è¿‡æ‹Ÿåˆæ—¶ï¼Œä½ ä¼šå‘ç°è®­ç»ƒæŸå¤±ç»§ç»­ä¸‹é™ï¼Œä½†æ˜¯éªŒè¯æŸå¤±å¼€å§‹ä¸Šå‡ã€‚
# 
# ### é€‰æ‹©å­¦ä¹ é€Ÿç‡
# 
# é€Ÿç‡å¯ä»¥è°ƒæ•´æƒé‡æ›´æ–°å¹…åº¦ã€‚å¦‚æœé€Ÿç‡å¤ªå¤§ï¼Œæƒé‡å°±ä¼šå¤ªå¤§ï¼Œå¯¼è‡´ç½‘ç»œæ— æ³•ä¸æ•°æ®ç›¸æ‹Ÿåˆã€‚å»ºè®®ä» 0.1 å¼€å§‹ã€‚å¦‚æœç½‘ç»œåœ¨ä¸æ•°æ®æ‹Ÿåˆæ—¶é‡åˆ°é—®é¢˜ï¼Œå°è¯•é™ä½å­¦ä¹ é€Ÿç‡ã€‚æ³¨æ„ï¼Œå­¦ä¹ é€Ÿç‡è¶Šä½ï¼Œæƒé‡æ›´æ–°çš„æ­¥é•¿å°±è¶Šå°ï¼Œç¥ç»ç½‘ç»œæ”¶æ•›çš„æ—¶é—´å°±è¶Šé•¿ã€‚
# 
# 
# ### é€‰æ‹©éšè—èŠ‚ç‚¹æ•°é‡
# 
# éšè—èŠ‚ç‚¹è¶Šå¤šï¼Œæ¨¡å‹çš„é¢„æµ‹ç»“æœå°±è¶Šå‡†ç¡®ã€‚å°è¯•ä¸åŒçš„éšè—èŠ‚ç‚¹çš„æ•°é‡ï¼Œçœ‹çœ‹å¯¹æ€§èƒ½æœ‰ä½•å½±å“ã€‚ä½ å¯ä»¥æŸ¥çœ‹æŸå¤±å­—å…¸ï¼Œå¯»æ‰¾ç½‘ç»œæ€§èƒ½æŒ‡æ ‡ã€‚å¦‚æœéšè—å•å…ƒçš„æ•°é‡å¤ªå°‘ï¼Œé‚£ä¹ˆæ¨¡å‹å°±æ²¡æœ‰è¶³å¤Ÿçš„ç©ºé—´è¿›è¡Œå­¦ä¹ ï¼Œå¦‚æœå¤ªå¤šï¼Œåˆ™å­¦ä¹ æ–¹å‘å°±æœ‰å¤ªå¤šçš„é€‰æ‹©ã€‚é€‰æ‹©éšè—å•å…ƒæ•°é‡çš„æŠ€å·§åœ¨äºæ‰¾åˆ°åˆé€‚çš„å¹³è¡¡ç‚¹ã€‚

# In[42]:


import sys

### Set the hyperparameters here ###
iterations = 2000
learning_rate = 1.0
hidden_nodes = 5
output_nodes = 1

N_i = train_features.shape[1]
network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)

losses = {'train':[], 'validation':[]}
for ii in range(iterations):
    # Go through a random batch of 128 records from the training data set
    batch = np.random.choice(train_features.index, size=128)
    X, y = train_features.ix[batch].values, train_targets.ix[batch]['cnt']
                             
    network.train(X, y)
    
    # Printing out the training progress
    train_loss = MSE(network.run(train_features).T, train_targets['cnt'].values)
    val_loss = MSE(network.run(val_features).T, val_targets['cnt'].values)
    sys.stdout.write("\rProgress: {:2.1f}".format(100 * ii/float(iterations))                      + "% ... Training loss: " + str(train_loss)[:5]                      + " ... Validation loss: " + str(val_loss)[:5])
    sys.stdout.flush()
    
    losses['train'].append(train_loss)
    losses['validation'].append(val_loss)


# In[43]:


plt.plot(losses['train'], label='Training loss')
plt.plot(losses['validation'], label='Validation loss')
plt.legend()
_ = plt.ylim()


# ## æ£€æŸ¥é¢„æµ‹ç»“æœ
# 
# ä½¿ç”¨æµ‹è¯•æ•°æ®çœ‹çœ‹ç½‘ç»œå¯¹æ•°æ®å»ºæ¨¡çš„æ•ˆæœå¦‚ä½•ã€‚å¦‚æœå®Œå…¨é”™äº†ï¼Œè¯·ç¡®ä¿ç½‘ç»œä¸­çš„æ¯æ­¥éƒ½æ­£ç¡®å®ç°ã€‚

# In[44]:


fig, ax = plt.subplots(figsize=(8,4))

mean, std = scaled_features['cnt']
predictions = network.run(test_features).T*std + mean
ax.plot(predictions[0], label='Prediction')
ax.plot((test_targets['cnt']*std + mean).values, label='Data')
ax.set_xlim(right=len(predictions))
ax.legend()

dates = pd.to_datetime(rides.ix[test_data.index]['dteday'])
dates = dates.apply(lambda d: d.strftime('%b %d'))
ax.set_xticks(np.arange(len(dates))[12::24])
_ = ax.set_xticklabels(dates[12::24], rotation=45)


# ## å¯é€‰ï¼šæ€è€ƒä¸‹ä½ çš„ç»“æœï¼ˆæˆ‘ä»¬ä¸ä¼šè¯„ä¼°è¿™é“é¢˜çš„ç­”æ¡ˆï¼‰
# 
#  
# è¯·é’ˆå¯¹ä½ çš„ç»“æœå›ç­”ä»¥ä¸‹é—®é¢˜ã€‚æ¨¡å‹å¯¹æ•°æ®çš„é¢„æµ‹æ•ˆæœå¦‚ä½•ï¼Ÿå“ªé‡Œå‡ºç°é—®é¢˜äº†ï¼Ÿä¸ºä½•å‡ºç°é—®é¢˜å‘¢ï¼Ÿ
# 
# > **æ³¨æ„**ï¼šä½ å¯ä»¥é€šè¿‡åŒå‡»è¯¥å•å…ƒç¼–è¾‘æ–‡æœ¬ã€‚å¦‚æœæƒ³è¦é¢„è§ˆæ–‡æœ¬ï¼Œè¯·æŒ‰ Control + Enter
# 
# #### è¯·å°†ä½ çš„ç­”æ¡ˆå¡«å†™åœ¨ä¸‹æ–¹
# 
# è¿™ä¸ªæ¨¡å‹åœ¨å‰20å¤©ï¼ˆ12æœˆ11æ—¥è‡³12æœˆ20æ—¥ï¼‰çš„é¢„æµ‹æ•ˆæœæŒºå¥½çš„ï¼Œä½†åœ¨12æœˆ21æ—¥åé¢„æµ‹æ•ˆæœä¸‹é™ï¼Œå¯èƒ½åŸå› æ˜¯å½“æ—¶æ¥è¿‘åœ£è¯èŠ‚ï¼Œä½¿ç”¨å…±äº«å•è½¦çš„äººæ•°ä¸‹é™ï¼Œå¯¼è‡´æ¨¡å‹æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥è¿›è¡Œè®­ç»ƒã€‚
