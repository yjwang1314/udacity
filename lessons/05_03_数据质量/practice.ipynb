{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件很大，不要运行，仅供参考\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "osm_file = open(\"chicago_illinois.osm\", \"r\")\n",
    "\n",
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "street_types = defaultdict(int)\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "\n",
    "        street_types[street_type] += 1\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v) \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit():\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        if is_street_name(elem):\n",
    "            audit_street_type(street_types, elem.attrib['v'])    \n",
    "    print_sorted_dict(street_types)    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  修正有效性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "  你的任务是检查 DBPedia 自动数据文件的“productionStartYear”并获取有效的值。应该完成以下任务：\n",
    "-    检查字段“productionStartYear”是否包含年份\n",
    "-    检查该年份是否在 1886 至 2014 范围内\n",
    "-    将字段值转换为年份（而不是整个日期时间）\n",
    "-    字段的其他部分和值应该保持不变\n",
    "-    如果字段的值是如上所述范围内的有效年份，则将该行写入 output_good 文件中\n",
    "-    如果字段的值不是如上所述的有效年份，则将该行写入 output_bad 文件中\n",
    "-    你应该采用提供的数据读取和写入方式（DictReader 和 DictWriter），它们将会对标题进行处理。\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "你可以编写辅助函数来检查数据并编写文件，但是我们将仅调用包含三个参数（inputfile、output_good、output_bad）的“process_file”文件。\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "    # store data into lists for output\n",
    "    data_good = []\n",
    "    data_bad = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        for row in reader:\n",
    "            # validate URI value\n",
    "            if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                continue # 跳出本次循环\n",
    "\n",
    "            ps_year = row['productionStartYear'][:4]\n",
    "            try: # use try/except to filter valid items\n",
    "                ps_year = int(ps_year)\n",
    "                row['productionStartYear'] = ps_year\n",
    "                if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "                    data_good.append(row)\n",
    "                else:\n",
    "                    data_bad.append(row)\n",
    "            except ValueError: # non-numeric strings caught by exception\n",
    "                if ps_year == 'NULL':\n",
    "                    data_bad.append(row)\n",
    "\n",
    "    # Write processed data to output files\n",
    "    with open(output_good, \"w\") as good:\n",
    "        writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_good:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    with open(output_bad, \"w\") as bad:\n",
    "        writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_bad:\n",
    "            writer.writerow(row) \n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 习题集\n",
    "## 审查数据质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'areaCode': set([<type 'int'>, <type 'NoneType'>, <type 'str'>]),\n",
      " 'areaLand': set([<type 'float'>, <type 'list'>, <type 'NoneType'>]),\n",
      " 'areaMetro': set([<type 'float'>, <type 'NoneType'>]),\n",
      " 'areaUrban': set([<type 'float'>, <type 'NoneType'>]),\n",
      " 'elevation': set([<type 'float'>, <type 'list'>, <type 'NoneType'>]),\n",
      " 'governmentType_label': set([<type 'NoneType'>, <type 'str'>]),\n",
      " 'homepage': set([<type 'NoneType'>, <type 'str'>]),\n",
      " 'isPartOf_label': set([<type 'list'>, <type 'NoneType'>, <type 'str'>]),\n",
      " 'maximumElevation': set([<type 'NoneType'>]),\n",
      " 'minimumElevation': set([<type 'NoneType'>]),\n",
      " 'name': set([<type 'list'>, <type 'NoneType'>, <type 'str'>]),\n",
      " 'populationDensity': set([<type 'float'>, <type 'list'>, <type 'NoneType'>]),\n",
      " 'populationTotal': set([<type 'int'>, <type 'NoneType'>]),\n",
      " 'timeZone_label': set([<type 'NoneType'>, <type 'str'>]),\n",
      " 'utcOffset': set([<type 'int'>,\n",
      "                   <type 'list'>,\n",
      "                   <type 'NoneType'>,\n",
      "                   <type 'str'>]),\n",
      " 'wgs84_pos#lat': set([<type 'float'>]),\n",
      " 'wgs84_pos#long': set([<type 'float'>])}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up. In the first exercise we want you to audit\n",
    "the datatypes that can be found in some particular fields in the dataset.\n",
    "The possible types of values can be:\n",
    "- NoneType if the value is a string \"NULL\" or an empty string \"\"\n",
    "- list, if the value starts with \"{\"\n",
    "- int, if the value can be cast to int\n",
    "- float, if the value can be cast to float, but CANNOT be cast to int.\n",
    "   For example, '3.23e+07' should be considered a float because it can be cast\n",
    "   as float but int('3.23e+07') will throw a ValueError\n",
    "- 'str', for all other values\n",
    "在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "在第一道练习中，请审核数据集中某些特定字段中的数据类型。\n",
    "值类型可以是：\n",
    "-    NoneType，如果值是字符串“NULL”或空字符串“”\n",
    "-    列表，如果值以“{”开头\n",
    "-    整型，如果值可以转型为整型\n",
    "-    浮点型，如果值可以转型为浮点型，但是无法转型为整型。\n",
    "例如，“3.23e+07”应该被当做浮点型，因为可以转型为浮点型，但是int('3.23e+07') \n",
    "将抛出 ValueError\n",
    "-    “str”，表示其他所有值\n",
    "\n",
    "The audit_file function should return a dictionary containing fieldnames and a \n",
    "SET of the types that can be found in the field. e.g.\n",
    "{\"field1\": set([type(float()), type(int()), type(str())]),\n",
    " \"field2\": set([type(str())]),\n",
    "  ....\n",
    "}\n",
    "The type() function returns a type object describing the argument given to the \n",
    "function. You can also use examples of objects to create type objects, e.g.\n",
    "type(1.1) for a float: see the test function below for examples.\n",
    "\n",
    "audit_file 函数应该返回一个字典，其中包含字段名称和可以在该字段中找到的类型集。例如\n",
    "\n",
    "{\"field1\": set([type(float()), type(int()), type(str())]),\n",
    " \"field2\": set([type(str())]),\n",
    "  ....\n",
    "}\n",
    "type() 函数返回的是类型对象，描述了提供给该函数的参数。你还可以使用对象示例创建类型对象，\n",
    "例如 type(1.1) 表示浮点型：具体示例请参阅下面的测试函数。\n",
    "\n",
    "Note that the first three rows (after the header row) in the cities.csv file\n",
    "are not actual data points. The contents of these rows should note be included\n",
    "when processing data types. Be sure to include functionality in your code to\n",
    "skip over or detect these rows.\n",
    "注意，cities.csv 文件的前三行（标题行之后）不是实际的数据点。在处理数据类型时，不应该\n",
    "包含这些行的内容。确保在代码中包含相关功能，以便跳过或检测出这些行。\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for field in fields:\n",
    "        fieldtypes_tmp = []\n",
    "        with open(filename) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                # validate URI value\n",
    "                if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                    continue\n",
    "                try:\n",
    "                    if row[field][0] == '{':\n",
    "                        fieldtypes_tmp.append(type([]))\n",
    "                    elif row[field] == 'NULL' or '':\n",
    "                        fieldtypes_tmp.append(type(None))\n",
    "                    elif int(row[field]):\n",
    "                        fieldtypes_tmp.append(type(int()))\n",
    "                    else:\n",
    "                        fieldtypes_tmp.append(type(str()))\n",
    "\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        if float(row[field]):\n",
    "                            fieldtypes_tmp.append(type(float()))\n",
    "                        else:\n",
    "                            pass\n",
    "                    except ValueError:\n",
    "                        fieldtypes_tmp.append(type(str()))\n",
    "        fieldtypes[field] = set(fieldtypes_tmp)\n",
    "\n",
    "    return fieldtypes\n",
    "\n",
    "\n",
    "def test():\n",
    "    fieldtypes = audit_file(CITIES, FIELDS)\n",
    "\n",
    "    pprint.pprint(fieldtypes)\n",
    "\n",
    "    assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
    "    assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修复区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing three example results:\n",
      "None\n",
      "101787000.0\n",
      "31597900.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "\n",
    "Since in the previous quiz you made a decision on which value to keep for the\n",
    "\"areaLand\" field, you now know what has to be done.\n",
    "因为在上一道测验中，你已经决定针对“areaLand”字段保留哪个值，你现在知道该如何操作了。\n",
    "\n",
    "Finish the function fix_area(). It will receive a string as an input, and it\n",
    "has to return a float representing the value of the area or None.\n",
    "You have to change the function fix_area. You can use extra functions if you\n",
    "like, but changes to process_file will not be taken into account.\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "完成函数 fix_area()。它将获得字符串输入，并需要返回表示面积值的浮点值或 None。\n",
    "你需要更改fix_area 函数。你可以使用其他函数，但是对 process_file 的更改不会计入评估范围。\n",
    "代码的其余部分只是用来展示可以如何使用该函数的示例。\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "# 选择小数位数更精确的数据\n",
    "def fix_area(area):\n",
    "    if area == 'NULL':\n",
    "        area = None\n",
    "    elif area[0] == '{':\n",
    "        areaLen = lambda x: len(re.findall(re.compile('(\\d\\.\\d+?)e'), x)[0]) # 计算小数位数\n",
    "        area_list = area[1:-1].split('|')\n",
    "        area_fine = area_list[np.argmax(map(areaLen, area_list))]\n",
    "        area = float(area_fine)\n",
    "    else:\n",
    "        area = float(area)\n",
    "    return area\n",
    "\n",
    "def process_file(filename):\n",
    "    # CHANGES TO THIS FUNCTION WILL BE IGNORED WHEN YOU SUBMIT THE EXERCISE\n",
    "    data = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            if \"areaLand\" in line:\n",
    "                line[\"areaLand\"] = fix_area(line[\"areaLand\"])\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing three example results:\"\n",
    "    for n in range(5,8):\n",
    "        pprint.pprint(data[n][\"areaLand\"])\n",
    "\n",
    "    assert data[3][\"areaLand\"] == None        \n",
    "    assert data[8][\"areaLand\"] == 55166700.0\n",
    "    assert data[20][\"areaLand\"] == 14581600.0\n",
    "    assert data[33][\"areaLand\"] == 20564500.0    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修复姓名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 20 results:\n",
      "['Kud']\n",
      "['Kuju']\n",
      "['Kumbhraj']\n",
      "['Kumhari']\n",
      "['Kunigal']\n",
      "['Kurgunta']\n",
      "['Athens']\n",
      "['Demopolis']\n",
      "['Chelsea Alabama']\n",
      "['Pell City Alabama']\n",
      "['City of Northport']\n",
      "['Sand Point']\n",
      "['Unalaska Alaska']\n",
      "['City of Menlo Park']\n",
      "['Negtemiut', 'Nightmute']\n",
      "['Fairbanks Alaska']\n",
      "['Homer']\n",
      "['Ketchikan Alaska']\n",
      "['Nuniaq', 'Old Harbor']\n",
      "['Rainier Washington']\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "\n",
    "In the previous quiz you recognized that the \"name\" value can be an array (or\n",
    "list in Python terms). It would make it easier to process and query the data\n",
    "later if all values for the name are in a Python list, instead of being\n",
    "just a string separated with special characters, like now.\n",
    "在上一道测验中，你意识到“name”值可以是数组（或用 Python 术语来说的话，是列表）。\n",
    "如果名称的所有值是 Python 列表（而不是用特殊字符分隔的字符串，例如现在的状况），则稍后更容易处理和查询数据。\n",
    "\n",
    "Finish the function fix_name(). It will recieve a string as an input, and it\n",
    "will return a list of all the names. If there is only one name, the list will\n",
    "have only one item in it; if the name is \"NULL\", the list should be empty.\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "请完成函数fix_name()。它将获得字符串输入，并返回所有名称列表。如果只有一个名称，列表将只有一项。\n",
    "如果名称是“NULL”，该列表应该为空。代码的其余部分只是可以用来展示如何使用该函数的示例。\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "\n",
    "def fix_name(name):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if name == 'NULL':\n",
    "        name = []\n",
    "    elif name[0] == '{':\n",
    "        name = name[1:-1].split('|')\n",
    "    else:\n",
    "        name = [name]\n",
    "    return name\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            if \"name\" in line:\n",
    "                line[\"name\"] = fix_name(line[\"name\"])\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing 20 results:\"\n",
    "    for n in range(20):\n",
    "        pprint.pprint(data[n][\"name\"])\n",
    "\n",
    "    assert data[14][\"name\"] == ['Negtemiut', 'Nightmute']\n",
    "    assert data[9][\"name\"] == ['Pell City Alabama']\n",
    "    assert data[3][\"name\"] == ['Kumhari']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉字段审查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "\n",
    "If you look at the full city data, you will notice that there are couple of\n",
    "values that seem to provide the same information in different formats: \"point\"\n",
    "seems to be the combination of \"wgs84_pos#lat\" and \"wgs84_pos#long\". However,\n",
    "we do not know if that is the case and should check if they are equivalent.\n",
    "如果你查看完整的城市数据，会发现有几个值似乎提供的是同一信息，只是格式不同：\n",
    "“point”似乎是“wgs84_pos#lat”和“wgs84_pos#long”的结合体。但是，我们不知道是否是这种情况，\n",
    "你应该检查它们是否相等。\n",
    "\n",
    "Finish the function check_loc(). It will recieve 3 strings: first, the combined\n",
    "value of \"point\" followed by the separate \"wgs84_pos#\" values. You have to\n",
    "extract the lat and long values from the \"point\" argument and compare them to\n",
    "the \"wgs84_pos# values, returning True or False.\n",
    "完成函数check_loc()。它应该获得 3 个字符串：首先是“point”的值后面跟上单独的“wgs84_pos#”值。\n",
    "你应该从“point”参数中提取lat和长值，并将它们与“wgs84_pos#”值对比，返回 True 或 False。\n",
    "\n",
    "Note that you do not have to fix the values, only determine if they are\n",
    "consistent. To fix them in this case you would need more information. Feel free\n",
    "to discuss possible strategies for fixing this on the discussion forum.\n",
    "注意，你不需要修正这些值，只需判断它们是否保持一致。要修正这些值，你需要更多信息。欢迎在论坛上讨论如何修正这些值。\n",
    "\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "Changes to \"process_file\" function will not be taken into account for grading.\n",
    "代码的其余部分只是可以用来展示如何使用该函数的示例。我们在打分时，不会考虑对“process_file”函数做出的更改。\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "\n",
    "def check_loc(point, lat, longi):\n",
    "    # YOUR CODE HERE\n",
    "    return point == lat + ' ' + longi\n",
    "    # pass\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra matadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to check the location\n",
    "            result = check_loc(line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            if not result:\n",
    "                print \"{}: {} != {} {}\".format(line[\"name\"], line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    assert check_loc(\"33.08 75.28\", \"33.08\", \"75.28\") == True\n",
    "    assert check_loc(\"44.57833333333333 -91.21833333333333\", \"44.5783\", \"-91.2183\") == False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
